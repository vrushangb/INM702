{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05bc207a",
   "metadata": {},
   "source": [
    "TASK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "350ba4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b040f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3ea4c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
      "x_train shape: (10000, 28, 28) y_train shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"x_train shape:\", X_test.shape, \"y_train shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651f1600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29357fe5b50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[28286])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb586aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50000) (10000, 784)\n",
      "(10, 50000) (10, 10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],-1).T[:,: -10000]\n",
    "X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "\n",
    "y_tr = np.zeros((y_train.shape[0],10))\n",
    "y_tr[np.arange(y_train.size),y_train] = 1\n",
    "y_val = y_tr.T[:,: -10000]\n",
    "y_train = y_tr.T[:,: -10000]\n",
    "\n",
    "y_ts = np.zeros((y_test.shape[0],10))\n",
    "y_ts[np.arange(y_test.size), y_test] = 1\n",
    "y_test = y_ts.T\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a2fcb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "[0. 0. 0. ... 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train[0]))\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82dcda04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0bb74ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m42\u001b[0m\n\u001b[1;33m    def mult(self, a, b):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "#activation_function = sigmoid\n",
    "#activation_derivative = d_sigmoid\n",
    "\n",
    "from scipy.stats import truncnorm\n",
    "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm(\n",
    "        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def sigmoid(self, X):\n",
    "        return 1/(1+np.exp(-X))\n",
    "    \n",
    "    def derivsigmoid(self,X):\n",
    "        return X * (1 - X)\n",
    "    \n",
    "    def relu(self, X):\n",
    "      return max(0,X)\n",
    "\n",
    "    def softmax(self, X):\n",
    "\n",
    "      print(X)\n",
    "      for j in range (len(X[0])):\n",
    "        \n",
    "        sumexp = 0\n",
    "        for i in range (len(X)):\n",
    "          sumexp += np.exp(X[i][j])\n",
    "          \n",
    "        for i in range (len(X)):\n",
    "          X[i][j] = np.exp(X[i][j]) / sumexp\n",
    "      return X  \n",
    "def crossentropy(self, X, y):\n",
    "      #closs = copy.deepcopy(X)\n",
    "      loss = 0\n",
    "      for j in range (len(X[0])):\n",
    "        for i in range (len(X)):\n",
    "          loss += np.log(X[i][j]) * y[i][j]\n",
    "      return loss * (-1)\n",
    "      \n",
    "    def mult(self, a, b):\n",
    "      return a*b\n",
    "\n",
    "    def square(a):\n",
    "      return 0.5(a**2)\n",
    "    \n",
    "    def __init__(self, \n",
    "                 no_of_in_nodes, no_of_out_nodes, \n",
    "                 no_of_hidden_nodes, learning_rate):\n",
    "        \n",
    "        self.no_of_in_nodes = no_of_in_nodes\n",
    "        self.no_of_out_nodes = no_of_out_nodes\n",
    "        self.no_of_hidden_nodes = no_of_hidden_nodes\n",
    "        self.learning_rate = learning_rate \n",
    "        self.create_weight_matrices()\n",
    "        \n",
    "    def create_weight_matrices(self):\n",
    "        \"\"\" A method to initialize the weight matrices of the neural network\"\"\"\n",
    "        rad = 0.5 \n",
    "        X = truncated_normal(mean=1, sd=1, low=-rad, upp=rad)\n",
    "        self.weights_in_hidden = X.rvs((self.no_of_hidden_nodes, \n",
    "                                       self.no_of_in_nodes))\n",
    "        rad = 0.5 \n",
    "        X = truncated_normal(mean=1, sd=1, low=-rad, upp=rad)\n",
    "        self.weights_hidden_out = X.rvs((self.no_of_out_nodes, \n",
    "                                        self.no_of_hidden_nodes))\n",
    "         def train(self, input_vector, target_vector,epochs=10):\n",
    "        # input_vector and target_vector can be tuple, list or ndarray\n",
    "        \n",
    "        input_vector = np.array(input_vector, ndmin=2)\n",
    "        target_vector = np.array(target_vector, ndmin=2)\n",
    "        \n",
    "        vecder = np.vectorize(self.derivsigmoid)\n",
    "        vecact = np.vectorize(self.sigmoid)\n",
    "        vecmult = np.vectorize(self.mult)\n",
    "        vecsqer = np.vectorize(self.square)\n",
    "        #vecsoft = np.vectorize(self.softmax)\n",
    "        print(\"Test , \", target_vector[:100])\n",
    "        for i in range(epochs):\n",
    "        \n",
    "            print(\"IP Vec\",len(input_vector),\" and \", len(input_vector[0]))\n",
    "            # forward pass\n",
    "            output_vector1 = np.dot(self.weights_in_hidden, input_vector)\n",
    "            print(\"OP Vec1\",len(output_vector1),\" and \", len(output_vector1[0]))\n",
    "            \n",
    "            output_vector_hidden = vecact(output_vector1)\n",
    "\n",
    "            output_vector2 = np.dot(self.weights_hidden_out, output_vector_hidden)\n",
    "            print(\"OP Vec2\",len(output_vector2),\" and \", len(output_vector2[0]))\n",
    "            #print(\"Op last layer \",output_vector2)\n",
    "            #output_vector_network = vecact(output_vector2)\n",
    "            #output_vector_network = vecsoft(output_vector2)\n",
    "            output_vector_network = self.softmax(output_vector2)\n",
    "            #convert softmax op to label values!!!!!!!\n",
    "            print(output_vector_network[0][1],\" and sum =1?? \", output_vector_network[1][1])\n",
    "            \n",
    "            # derivative of the loss\n",
    "            #loss = \n",
    "            output_errors = target_vector - output_vector_network#vecsqer(loss) #self.crossentropy(output_vector_network, target_vector)\n",
    "            print(\"OP Errors -> \",output_errors)\n",
    "             # derivative of the activation function\n",
    "            derivative_output = vecder (output_vector_network)  # derivative here \n",
    "            \n",
    "            tmp = output_errors * derivative_output    #vecmult(derivative_output, output_errors) \n",
    "            # multiply with the previous activation (output_vector_hidden)\n",
    "            who_update = self.learning_rate * np.dot(tmp, output_vector_hidden.T)\n",
    "\n",
    "            # calculate hidden errors:\n",
    "            hidden_errors = np.dot(self.weights_hidden_out.T, output_errors * derivative_output )\n",
    "\n",
    "            derivative_hidden = vecder(output_vector_hidden)    \n",
    "            tmp = hidden_errors * derivative_hidden \n",
    "            wih_update = self.learning_rate * np.dot(tmp, input_vector.T)\n",
    "\n",
    "            # update the weights:\n",
    "            self.weights_in_hidden += wih_update\n",
    "            self.weights_hidden_out += who_update\n",
    "\n",
    "\n",
    "    def run(self, input_vector):\n",
    "        # input_vector can be tuple, list or ndarray\n",
    "        vecder = np.vectorize(self.derivsigmoid)\n",
    "        vecact = np.vectorize(self.sigmoid)\n",
    "        #vecsoft = np.vectorize(self.softmax)\n",
    "\n",
    "        \n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        output_vector = np.dot(self.weights_in_hidden, input_vector)\n",
    "        output_vector = vecact(output_vector)\n",
    "        \n",
    "        output_vector = np.dot(self.weights_hidden_out, output_vector)\n",
    "        #output_vector = vecsoft(output_vector)\n",
    "        output_vector = self.softmax(output_vector)\n",
    "        \n",
    "        return output_vector.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "126de509",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NeuralNetwork' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-ae39ddad098a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m simple_network = NeuralNetwork(no_of_in_nodes=28*28, \n\u001b[0m\u001b[0;32m      2\u001b[0m                                \u001b[0mno_of_out_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                \u001b[0mno_of_hidden_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                learning_rate=0.01)\n\u001b[0;32m      5\u001b[0m \u001b[0msimple_network\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NeuralNetwork' is not defined"
     ]
    }
   ],
   "source": [
    "simple_network = NeuralNetwork(no_of_in_nodes=28*28, \n",
    "                               no_of_out_nodes=10, \n",
    "                               no_of_hidden_nodes=4,\n",
    "                               learning_rate=0.01)\n",
    "simple_network.train(X_train,y_train)\n",
    "\n",
    "y_hat = simple_network.run(X_test)\n",
    "print(\"The type is\",type(y_hat))\n",
    "\n",
    "# converting softmax values to labels\n",
    "op = copy.deepcopy(y_hat)\n",
    "def convertop(y,op):\n",
    "  for i in range (len(y)):\n",
    "      maxv = -1\n",
    "      posi = posj = -1\n",
    "      for j in range(len(y[0])):\n",
    "          #print(j)\n",
    "          if y[i][j]>maxv:\n",
    "              maxv = y[i][j]\n",
    "              posi = i\n",
    "              posj = j\n",
    "          op[i][j] = 0\n",
    "      op[posi][posj] = 1\n",
    "  return op\n",
    "\n",
    "ycheck = convertop(y_hat,op)\n",
    "#print(\"Acc1 = \",sum(ycheck==y_test)/len(ycheck))\n",
    "\n",
    "\n",
    "\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91d7815f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_hat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-05ca870d22a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m933\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_hat' is not defined"
     ]
    }
   ],
   "source": [
    "print(y_hat[933])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05767244",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ycheck[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "newy = y_test.T\n",
    "print(newy[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bd6b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newy.shape)\n",
    "print(len(newy))\n",
    "print(ycheck.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb175b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range (len(newy)):\n",
    "  for j in range (len(newy[0])):\n",
    "    if newy[i][j] == 1 and ycheck [i][j] == 1:\n",
    "      #print(\"yes\")\n",
    "      count += 1\n",
    "\n",
    "print(\"Accuracy = {} %\".format(count/len(newy)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
